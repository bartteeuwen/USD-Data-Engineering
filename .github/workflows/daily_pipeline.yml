name: USD Data Engineering Pipeline

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */4 * * *"

jobs:
  run-data-pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Run Ingestion Script
        env:
          ADZUNA_APP_ID: ${{ secrets.ADZUNA_APP_ID }}
          ADZUNA_APP_KEY: ${{ secrets.ADZUNA_APP_KEY }}
        run: python ingestion/get_adzuna_jobs.py

      - name: Load Fortune 500 -> BigQuery
        run: |
          bq load --replace --skip_leading_rows=1 \
            usd-data-engineering:labor_market.dim_fortune_500 \
            "data/Fortune_500.csv" \
            rank:INTEGER,company:STRING,industry:STRING,city:STRING,state:STRING,zip:STRING,website:STRING,employees:STRING,revenue:STRING,ceo:STRING

      - name: Run SQL Transformations
        run: |
          bq query --use_legacy_sql=false < transformation/01_dim_fortune_500.sql
          bq query --use_legacy_sql=false < transformation/02_match_skills.sql
          bq query --use_legacy_sql=false < transformation/03_enrich_skills_in_demand.sql
          bq query --use_legacy_sql=false < transformation/04_extract_details.sql
          bq query --use_legacy_sql=false < transformation/05_aggregate_counts.sql
          bq query --use_legacy_sql=false < transformation/06_enrich_skill_counts.sql